# 序列化与反序列化
序列化：从内存中保存到硬盘中
![image.png](https://kashiwa-pic.oss-cn-beijing.aliyuncs.com/20240306152256.png)
8个有序字典保存信息，parameter储存的是学习到的参数信息，推荐第二种方法
![image.png](https://kashiwa-pic.oss-cn-beijing.aliyuncs.com/20240306152336.png)

# 断点续训练
定期保存模型和优化器(momentum)的数据
![image.png](https://kashiwa-pic.oss-cn-beijing.aliyuncs.com/20240306153005.png)

```
# ============================ step 5+/5 断点恢复 ============================

  

path_checkpoint = "./checkpoint_4_epoch.pkl"

checkpoint = torch.load(path_checkpoint)

  

net.load_state_dict(checkpoint['model_state_dict'])

  

optimizer.load_state_dict(checkpoint['optimizer_state_dict'])

  

start_epoch = checkpoint['epoch']

  

scheduler.last_epoch = start_epoch
```